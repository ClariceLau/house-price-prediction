---
title: "Untitled"
output: html_document
date: "2023-05-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(arules)
library(caret)
library(catboost)
library(cluster)
library(dplyr)
library(e1071)
library(factoextra)
library(ggplot2)
library(glmnet)
library(lattice)
library(lightgbm)
library(mlrMBO)
library(randomForest)
library(tidyr)
library(viridis)
library(xgboost)
library(Metrics)
library(Rtsne)
```

```{r}
source("data_cleaning.r")
```

## Data Transformation/Scaling

Split the numerical variables into features and the target variable.

```{r}
X_num <- subset(numerical_data, select = -c(SalePrice))
y <- subset(numerical_data, select = c(SalePrice))$SalePrice
```

Log Transformation for numerical features.

```{r}
skewness_before <- sapply(X_num, function(x) {
  e1071::skewness(x)
})

X_num_skewed <- skewness_before[abs(skewness_before) > 0.75]

for (x in names(X_num_skewed)) {
  # bc <- BoxCoxTrans(X_num[[x]], lambda = 0.15)
  # X_num[[x]] <- predict(bc, X_num[[x]])
  X_num[[x]] <- log1p(X_num[[x]])
}

skewness_after <- sapply(X_num, function(x) {
  e1071::skewness(x)
})

data.frame(skewness_before, skewness_after)
```

Log Transformation for the target variable.

```{r}
skewness_before <- e1071::skewness(y)

y_t <- log1p(y)

skewness_after <- e1071::skewness(y_t)

sprintf("Before: %f, After: %f", skewness_before, skewness_after)
```

Scaling

```{r}
X_num <- scale(X_num)
```

One-Hot Encoding for categorical variables.

```{r}
encoder <- dummyVars(~., data = categorical_data)

X_cat <- predict(encoder, newdata = categorical_data)
X_cat <- data.frame(X_cat)
```

Split into train and validation and test sets.

```{r}
X <- cbind(X_cat, X_num)

train_idx <- createDataPartition(y_t, p = 0.7, list = F)
X_train <- X[train_idx, ]
y_train <- y_t[train_idx]

X_test <- X[-train_idx, ]
y_test <- y_t[-train_idx]

train_val_idx <- createDataPartition(y_train, p = 0.8, list = FALSE)
X_train <- X_train[train_val_idx, ]
y_train <- y_train[train_val_idx]

X_val <- X_train[-train_val_idx, ]
y_val <- y_train[-train_val_idx]
```

```{r}
dim(X)
length(y)

dim(X_train)
length(y_train)

dim(X_val)
length(y_val)

names(X)
```

## Clustering

### PCA
```{r}
# Load the necessary libraries
library(stats)
library(factoextra)

# Perform PCA on the data matrix
pca_result <- prcomp(X)

# Extract the principal components
principal_components <- as.data.frame(pca_result$x)

# Determine the optimal number of clusters using the elbow method
fviz_nbclust(principal_components, kmeans, method = "wss")

k <- 3
# Perform K-means clustering on the principal components
kmeans_result <- kmeans(principal_components, centers = k)
cluster_assignments <- kmeans_result$cluster
print(cluster_assignments)

# Add the cluster assignments to the principal components data
principal_components$cluster <- as.factor(cluster_assignments)

ggplot(principal_components, aes(PC1, PC2, color = cluster)) +
  geom_point() +
  labs(x = "Principal Component 1", y = "Principal Component 2") +
  scale_color_discrete(name = "Cluster") +
 theme_minimal()
```

### t-SNE

```{r}
tsne <- Rtsne(X)
tsne_df <- data.frame(tsne)
```

```{r}
dist_mat <- dist(tsne$Y, method = "euclidean")
hclust_avg <- hclust(dist_mat, method = "average")

dend <- as.dendrogram(hclust_avg)
plot(dend)
```

```{r}
k = 15
cut_avg <- cutree(hclust_avg, k)
tsne_df$cluster <- cut_avg

getCentroid <- function(points) {
  xy <- numeric(2)
  
  xy[1] = mean(points[, 1])
  xy[2] = mean(points[, 2])

  return(xy)
}

centroids = matrix(0, k, 2)
for (i in unique(cut_avg)) centroids[i, ] <- getCentroid(tsne$Y[cut_avg == i,])
```

```{r}
tsne_df

ggplot(tsne_df, aes(x=Y.1, y=Y.2, color=y)) +
  geom_point() +
  scale_color_gradientn(colours = heat.colors(10))

ggplot(data.frame(table(tsne_df$cluster)), aes(x=Var1, y=Freq)) +
  geom_bar(stat = "identity") +
  coord_flip()

ggplot(tsne_df, aes(x=Y.1, y=Y.2, color=cluster)) +
  geom_point() +
  scale_color_viridis() +
  scale_fill_viridis(discrete = T) +
  geom_point(data = data.frame(centroids), aes(x=X1, y=X2), color="black", fill="white", shape=21, size=8) +
  geom_text(data = data.frame(centroids), aes(x=X1, y=X2, label=1:k), color="black")

fviz_silhouette(silhouette(cutree(hclust_avg, k = k), dist_mat))

```

## Baselines

```{r}
baselines_rmse <- list()
actual_metrics <- list()
baselines_rmse_test <- list()
actual_metrics_test <- list()

metrics_fusion <- function(y_pred, y) {
  y_pred_inv <- expm1(y_pred)
  y_inv <- expm1(y)

  a <- mae(y_pred_inv, y_inv)
  b <- mape(y_pred_inv, y_inv)
  c <- rmse(y_pred_inv, y_inv)
  d <- mse(y_pred_inv, y_inv)
  e <- R2(y_pred_inv, y_inv)

  return(c("mae" = a, "mape" = b, "rmse" = c, "mse" = d, "r2" = e))
}
```

### Linear Regression

```{r}
linreg <- lm(SalePrice ~ ., data = cbind(X_train, SalePrice = y_train))

# Validation predictions and metrics
y_pred_val <- predict(linreg, newdata = X_val)
score_val <- rmse(y_pred_val, y_val)
baselines_rmse$linear_regression <- score_val
actual_metrics$linear_regression <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- predict(linreg, newdata = X_test)
score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$linear_regression <- score_test
actual_metrics_test$linear_regression <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

### Lasso Regression

```{r}
lasso <- cv.glmnet(x = as.matrix(X_train), y = y_train, alpha = 1)

# Validation predictions and metrics
y_pred_val <- predict(lasso, newx = as.matrix(X_val))
score_val <- rmse(y_pred_val, y_val)
baselines_rmse$lasso <- score_val
actual_metrics$lasso <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- predict(lasso, newx = as.matrix(X_test))
score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$lasso <- score_test
actual_metrics_test$lasso <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

### Ridge Regression

```{r}
ridge <- cv.glmnet(x = as.matrix(X_train), y = y_train, alpha = 0)

# Validation predictions and metrics
y_pred_val <- predict(ridge, newx = as.matrix(X_val))
score_val <- rmse(y_pred_val, y_val)
baselines_rmse$ridge <- score_val
actual_metrics$ridge <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- predict(ridge, newx = as.matrix(X_test))
score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$ridge <- score_test
actual_metrics_test$ridge <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

### Elastic Net

```{r}
results <- data.frame()

for (i in 0:20) {
  elasticnet <- cv.glmnet(x = as.matrix(X_train), y = y_train, alpha = i/20)
  y_pred_val <- predict(elasticnet, newx = as.matrix(X_val))
  y_pred_test <- predict(elasticnet, newx = as.matrix(X_test))

  row <- data.frame(alpha = i/20, rmse_val = rmse(y_pred_val, y_val), rmse_test = rmse(y_pred_test, y_test))
  results <- rbind(results, row)
}

best_alpha <- results$alpha[which.min(results$rmse_val)]
score_val <- min(results$rmse_val)
score_test <- results$rmse_test[which.min(results$rmse_val)]

baselines_rmse$elasticnet <- score_val
baselines_rmse_test$elasticnet <- score_test

actual_metrics$elasticnet <- metrics_fusion(y_pred_val, y_val)
actual_metrics_test$elasticnet <- metrics_fusion(y_pred_test, y_test)

# Display scores
best_alpha
score_val
score_test
```

### K-Nearest Neighbors Regression

```{r}
knn <- knnreg(x = X_train, y = y_train)
y_pred_val <- predict(knn, newdata = X_val)
y_pred_test <- predict(knn, newdata = X_test)

score_val <- rmse(y_pred_val, y_val)
baselines_rmse$knn <- score_val
actual_metrics$knn <- metrics_fusion(y_pred_val, y_val)

score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$knn <- score_test
actual_metrics_test$knn <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

### Support Vector Regression

```{r}
svr <- e1071::svm(SalePrice ~ ., data = cbind(X_train, SalePrice = y_train))
y_pred_val <- predict(svr, newdata = X_val)
y_pred_test <- predict(svr, newdata = X_test)

score_val <- rmse(y_pred_val, y_val)
baselines_rmse$svr <- score_val
actual_metrics$svr <- metrics_fusion(y_pred_val, y_val)

score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$svr <- score_test
actual_metrics_test$svr <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

### Decision Tree

```{r}
dt <- caret::train(x = X_train, y = y_train, method = "rpart")
y_pred_val <- predict(dt, newdata = X_val)
y_pred_test <- predict(dt, newdata = X_test)

score_val <- rmse(y_pred_val, y_val)
baselines_rmse$decision_tree <- score_val
actual_metrics$decision_tree <- metrics_fusion(y_pred_val, y_val)

score_test <- rmse(y_pred_test, y_test)
baselines_rmse_test$decision_tree <- score_test
actual_metrics_test$decision_tree <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

## Ensemble Learning

```{r}
ensemble_rmse <- list()
ensemble_actual_metrics <- list()
ensemble_rmse_test <- list()
ensemble_actual_metrics_test <- list()
```

### Random Forest

```{r}
rf <- randomForest(x = X_train, y = y_train, ntree = 1000, proximity = TRUE)

# Validation predictions and metrics
y_pred_val <- predict(rf, newdata = X_val)
score_val <- rmse(y_pred_val, y_val)
ensemble_rmse$random_forest <- score_val
ensemble_actual_metrics$random_forest <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- predict(rf, newdata = X_test)
score_test <- rmse(y_pred_test, y_test)
ensemble_rmse_test$random_forest <- score_test
ensemble_actual_metrics_test$random_forest <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

```{r}
varImpPlot(rf)
```

### Gradient-Boosted Trees

```{r}
dtrain_val <- xgb.DMatrix(data = as.matrix(rbind(X_train, X_val)), label = c(y_train, y_val))
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)

xgb_params = list(
  eta = 0.01,
  gamma = 0.0468,
  max_depth = 6,
  min_child_weight = 1.41,
  subsample = 0.769,
  colsample_bytree = 0.283
)

xgb_cv <- xgb.cv(
  params = xgb_params,
  data = dtrain_val,
  nround = 10000,
  nfold = 5,
  prediction = F,
  showsd = T,
  metrics = "rmse",
  verbose = 1,
  print_every_n = 500,
  early_stopping_rounds = 25
)

# Validation predictions and metrics
score_val <- xgb_cv$evaluation_log$test_rmse_mean %>% min
ensemble_rmse$xgboost <- score_val

# Test predictions and metrics
xgb <- xgboost(
  params = xgb_params,
  data = dtrain_val,
  nround = 10000,
  eval_metric = "rmse",
  verbose = 1,
  print_every_n = 500,
  early_stopping_rounds = 25
)

y_pred_test <- predict(xgb, newdata = dtest)
score_test <- rmse(y_pred_test, y_test)
ensemble_rmse_test$xgboost_test <- score_test
ensemble_actual_metrics_test$xgboost_test <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

```{r}
objective_fn <- makeSingleObjectiveFunction(
  fn = function(x) {
    params = list(
      booster = "gbtree",
      eta = x["eta"],
      gamma = x["gamma"],
      max_depth = x["max_depth"],
      min_child_weight = x["min_child_weight"],
      subsample = x["subsample"],
      colsample_bytree = x["colsample_bytree"],
      max_delta_step = x["max_delta_step"]
    )

    cv <- xgb.cv(
      params = params,
      data = dtrain_val,
      nround = 10000,
      nfold = 5,
      prediction = F,
      showsd = T,
      metrics = "rmse",
      verbose = 1,
      print_every_n = 500,
      early_stopping_rounds = 25
    )

    cv$evaluation_log$test_rmse_mean %>% min
  },
  par.set = makeParamSet(
    makeNumericParam("eta", lower = 0.005, upper = 0.01),
    makeNumericParam("gamma", lower = 0.01, upper = 5),
    makeIntegerParam("max_depth", lower = 2, upper = 10),
    makeIntegerParam("min_child_weight", lower = 1, upper = 2000),
    makeNumericParam("subsample", lower = 0.20,  upper = 0.8),
    makeNumericParam("colsample_bytree", lower = 0.20, upper = 0.8),
    makeNumericParam("max_delta_step", lower = 0, upper = 5)
  ),
  minimize = TRUE
)

design <- generateDesign(n = 1000, par.set = getParamSet(objective_fn), fun = lhs::randomLHS)
control <- makeMBOControl() %>% setMBOControlTermination(., iters = 10)

run <- mbo(
  fun = objective_fn,
  design = design,
  learner = makeLearner("regr.km", predict.type = "se", covtype = "matern3_2", control = list(trace = FALSE)),
  control = control,
  show.info = TRUE
)
```
```{r}
lgb_train <- lgb.Dataset(data = as.matrix(X_train), label = y_train)
lgb_val <- lgb.Dataset(data = as.matrix(X_val), label = y_val)
lgb_test <- lgb.Dataset(data = as.matrix(X_test), label = y_test)

params <- list(
  objective = "regression",
  metric = "rmse",
  boosting_type = "gbdt",
  num_boost_round = 100,
  num_leaves = 31,
  learning_rate = 0.1,
  feature_fraction = 0.9,
  bagging_fraction = 0.8,
  bagging_freq = 5
)

lgb <- lgb.train(
  params = params,
  data = lgb_train,
  valids = list(val = lgb_val, test = lgb_test),
  early_stopping_rounds = 10,
  verbose = 0
)

# Validation predictions and metrics
y_pred_val <- predict(lgb, data = as.matrix(X_val))
score_val <- rmse(y_pred_val, y_val)
ensemble_rmse$lightgbm <- score_val
ensemble_actual_metrics$lightgbm <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- predict(lgb, data = as.matrix(X_test))
score_test <- rmse(y_pred_test, y_test)
ensemble_rmse_test$lightgbm <- score_test
ensemble_actual_metrics_test$lightgbm <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

```{r}
learn_pool <- catboost.load_pool(data = X_train, label = y_train)
val_pool <- catboost.load_pool(data = X_val, label = y_val)
test_pool <- catboost.load_pool(data = X_test, label = y_test)

params <- list(
  loss_function = "RMSE",
  iterations = 100,
  learning_rate = 0.1,
  depth = 10
)

catb <- catboost.train(
  params = params,
  data = learn_pool,
  eval_set = list(val = val_pool, test = test_pool)
)

# Validation predictions and metrics
y_pred_val <- catboost.predict(catb, val_pool)
score_val <- rmse(y_pred_val, y_val)
ensemble_rmse$catboost <- score_val
ensemble_actual_metrics$catboost <- metrics_fusion(y_pred_val, y_val)

# Test predictions and metrics
y_pred_test <- catboost.predict(catb, test_pool)
score_test <- rmse(y_pred_test, y_test)
ensemble_rmse_test$catboost <- score_test
ensemble_actual_metrics_test$catboost <- metrics_fusion(y_pred_test, y_test)

# Display scores
score_val
score_test
```

## Association Rule Mining on Housing Characteristics

```{r}
transactions <- transactions(categorical_data)
summary(transactions)
```

```{r}
inspect(head(transactions, n = 1))
```

```{r}
rules <- apriori(transactions, parameter = list(support = 0.95, confidence = 0.95))
```

```{r}
summary(rules)
```

```{r}
con <- file("data_description.txt", open = "r")

column_dictionary <- list()
value_dictionary <- list()

repeat {
  line <- readLines(con, n = 1)

  if (length(line) == 0) {
    break
  }

  first_character <- substr(line, 1, 1)

  if (first_character == "") {
    next
  }

  if (first_character != " ") {
    column_name <- sub(":.*", "", line)
    column_description <- trimws(sub(".*:", "", line))

    column_dictionary[[column_name]] <- column_description
    value_dictionary[[column_name]] <- list()
  } else {
    pairs <- unlist(strsplit(line, "\t"))
    key <- trimws(pairs[1])
    value <- trimws(pairs[2])

    value_dictionary[[column_name]][[key]] <- value
  }
}

close(con)
```

```{r}
rules_top_ten_df <- data.frame(
  lhs = labels(lhs(rules)),
  rhs = labels(rhs(rules)),
  rules@quality
) %>% arrange(desc(lift)) %>% head(n = 20)
```

```{r}
for (i in 1:nrow(rules_top_ten_df)) {
  row <- rules_top_ten_df[i, ]

  explanation <- ""
  lhs <- unlist(strsplit(gsub('^.|.$', '', row["lhs"]), ","))

  for (i in 1:length(lhs)) {
    pair <- unlist(strsplit(lhs[i], "="))
    key <- pair[1]
    value <- pair[2]

    key_t <- column_dictionary[[key]]
    value_t <- value_dictionary[[key]][[value]]

    if (i == 1) {
      explanation <- paste("IF", key_t, "=", value_t)
    } else {
      explanation <- paste(explanation, "AND", key_t, "=", value_t)
    }
  }

  rhs <- unlist(strsplit(gsub('^.|.$', '', row["rhs"]), "="))
  key <- rhs[1]
  value <- rhs[2]

  key_t <- column_dictionary[[key]]
  value_t <- value_dictionary[[key]][[value]]

  confidence_pct <- format(round(row["confidence"] * 100, 2), 2)

  explanation <- paste(explanation, "THEN", key_t, "=", value_t, "(Confidence:", paste0(confidence_pct, "%)"))
  print(explanation)
  cat("\n")
}
```

### Comparison

```{r}
# Convert baselines_rmse list to a data frame
print(baselines_rmse)
df <- data.frame(models = names(baselines_rmse), rmse = unlist(baselines_rmse))
# Create the bar chart using ggplot
ggplot(df, aes(x = models, y = rmse)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  xlab("Models") +
  ylab("RMSE") +
  ggtitle("Baseline RMSE") +
  theme_minimal()

print(ensemble_rmse)
df <- data.frame(models = names(ensemble_rmse), rmse = unlist(ensemble_rmse))
# Create the bar chart using ggplot
ggplot(df, aes(x = models, y = rmse)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  xlab("Models") +
  ylab("RMSE") +
  ggtitle("Ensemble RMSE") +
  theme_minimal()
```
```{r}
# Convert baselines_rmse_test list to a data frame
print(baselines_rmse_test)
df <- data.frame(models = names(baselines_rmse_test), rmse = unlist(baselines_rmse_test))
# Create the bar chart using ggplot
ggplot(df, aes(x = models, y = rmse)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  xlab("Models") +
  ylab("RMSE") +
  ggtitle("Baseline RMSE") +
  theme_minimal()

print(ensemble_rmse_test)
df <- data.frame(models = names(ensemble_rmse_test), rmse = unlist(ensemble_rmse_test))
# Create the bar chart using ggplot
ggplot(df, aes(x = models, y = rmse)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  xlab("Models") +
  ylab("RMSE") +
  ggtitle("Ensemble RMSE") +
  theme_minimal()
```

```{r}
data.frame(t(data.frame(actual_metrics))) %>% arrange(desc(r2))
data.frame(t(data.frame(actual_metrics_test))) %>% arrange(desc(r2))
```

```{r}
data.frame(t(data.frame(ensemble_actual_metrics))) %>% arrange(desc(r2))
data.frame(t(data.frame(ensemble_actual_metrics_test))) %>% arrange(desc(r2))
```
